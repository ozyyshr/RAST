<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reasoning Activation in LLMs via Small Model Transfer</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/RAST.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/RAST.png" style="width:1em;vertical-align: middle" alt="Logo"/> 
            <span class="mmmu" style="vertical-align: middle">RAST</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Reasoning Activation in LLMs via Small Model Transfer
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ozyyshr.github.io">Siru Ouyang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zhuxinyu.top/">Xinyu Zhu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://zilin.me/">Zilin Xiao</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://minhaoj2.github.io/">Minhao Jiang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://yumeng5.github.io/">Yu Meng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://hanj.cs.illinois.edu">Jiawei Han</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois Urbana-Champaign, <sup>2</sup>University of Virginia</span>
            <span class="author-block"><sup>3</sup>Rice University, <sup>4</sup>GE HealthCare</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ozyyshr/RAST/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#Analysis"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Examples</span>
                </a>
              </span>
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://x.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-twitter"></i>
                  </span>
                  <span>Twitter</span></a>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="content has-text-justified">
          <p>This project introduce <strong>RAST</strong>, a simple yet effective inference-time strategy that activates reasoning capabilities in LLMs by transferring logit-level adjustments from smaller RL-tuned models. Our paper begins with a key hypothesis as follows:</p>
        
          <p align="center">
            <img src="./static/images/hypothesis.png" class="center" width="80%">
            </p>
            
          <p>To test our hypothesis, we conduct a preliminary study using base LLM to do next token prediction when given prefix generated by the RL model, we found that there is a large path coverage rate, indicating that only a small set of tokens are different on the decoding path acorss model scales. In particular, the different tokens reflect certain reasoning behaviours, including <strong> (i) branching out</strong>, <strong> (ii) backtracking</strong>, and <strong>(iii) self-verification</strong>. </p>
          
          <p align="center">
            <img src="./static/images/intro.jpg" class="center" width="80%">
            </p>
          <!-- <br><br><strong>Project Features</strong>: 
          <ul>
            <li><strong>üöÄ Training-Free Methods</strong>
              <ul>
              <li> LoRA Switch and LoRA Composite enable dynamic and precise integration of multiple LoRAs without fine-tuning.</li> 
              <li> Unlike methods that merge LoRA weights, ours focuses on the decoding process, keeping all LoRA weights intact.</li>
              </ul>
            </li> 
            <li><strong>üìä ComposLoRA Testbed</strong>
              <ul>
              <li> A new comprehensive platform, featuring 480 composition sets and 22 pre-trained LoRAs across six categories.</li> 
              <li> ComposLoRA is designed for the quantitative evaluation of LoRA-based composable image generation tasks.</li>
              </ul>
            </li>
            <li><strong>üìù GPT-4V-based Evaluator</strong>
              <ul>
              <li>We propose using GPT-4V as an evaluator to assess the efficacy of compositions and the quality of images.</li>
              <li>This evaluator has demonstrated a better correlation with human judgments.</li>
              </ul>
            </li>
            <li><strong>üèÜ Superior Performance</strong>
              <ul>
              <li>Both automated and human evaluations show that our approaches substantially outperform the prevalent LoRA Merge.</li>
              <li>Our methods exhibit a more significant advantage when generating complex compositions.</li>
              </ul>
            </li>
            <li><strong>üïµÔ∏è‚Äç‚ôÇÔ∏è Detailed Analysis</strong>
              <ul>
              <li>We delve deeply into the scenarios where each method excels.</li>
              <li>We explore the potential bias associated with using GPT-4V for evaluation.</li>
              </ul>
            </li>
          </ul>
         </div> -->
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline width="80%">
        <source src="./static/videos/method.m4v"
                type="video/mp4">
      </video>
      <video id="teaser" autoplay muted loop playsinline width="100%">
        <source src="./static/videos/intro_video_2.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Multi-LoRA composition techniques effectively blend different elements into a cohesive image. Unlike the conventional LoRA Merge approach, which can lead to detail loss and image distortion as more LoRAs are added, our methods retain the accuracy of each element and the overall image quality.
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">
          <ul>
            <li><strong>Motivation:</strong>
              <ul>
              <li>RL boosts reasoning but is <strong>costly</strong> at scale.</li> 
              <li><strong>Key insight: </strong>RL shifts token distributions to favor reasoning, not add new knowledge.</li>
              <li><strong>Hypothesis: </strong>These shifts are model-size invariant and can be transferred.</li>
              <li><strong>Goal: </strong>Use a small RL model‚Äôs logits to activate reasoning in a large base model without retraining ‚Äî enabling efficient reasoning via RAST.</li>
              </ul>
            </li>
            <p align="center">
              <img src="./static/images/method.jpg" class="center" width="80%">
              </p>
            <li><strong>Reasoning Activation through Small RL Models:</strong>
              <ul>
                <li><strong>Core idea</strong>: Amplify reasoning-relevant tokens (e.g., ‚Äú<em>instead</em>‚Äù) while preserving base predictions for non-reasoning tokens (e.g., ‚Äú<em>of</em>‚Äù).</li>
                <li><strong>Mechanism</strong>: At each decoding step, apply the logit delta between <code>S<sub>RL</sub></code> and <code>S<sub>base</sub></code> to guide <code>M<sub>base</sub></code>.</li>
              </ul>
            </li>

            <p align="center">
              <img src="./static/images/equation.png" class="center" width="80%">
              </p>

            <!-- <li><strong>Confidence-based Review-and-Refinement:</strong>
              <ul>
              <li>The generated formulae and step-by-step reasoning are not always error-free. The cumulative errors in the formulae generation or step-by-step reasoning process can amplify and propagate throughout the entire generation, leading to wrong answers.</li>
              <li> We estimate a confidence score on the revision process. Only a high-confidence revision is accepted for further refinement in the next iteration.</li>
              </ul>
              <video id="teaser" autoplay muted loop playsinline width="80%">
                <source src="./static/videos/method.m4v"
                        type="video/mp4">
              </video>
            </li> -->
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Experimental Results</h2>
        <p align="center">
        <img src="./static/images/results.png" class="center" width="80%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li><strong>RAST enables scalable reasoning gains</strong>: It consistently improves pass@1 and recovery rates across model sizes without retraining, sometimes matching or surpassing RL models.</li>
            <li><strong>Stronger expert deltas yield greater improvement</strong>: Using <code>ŒîR</code> from larger RL models (e.g., 14B) leads to better reasoning performance, showing that delta logits encode richer reasoning signals.</li>
            <li><strong>There is a trade-off between base model and delta compatibility</strong>: While stronger base models benefit more, excessively mismatched pairs (e.g., 32B base with <code>ŒîR</code> from 7B) may hinder transfer effectiveness.</li>
          </ul>
        </div>
        <p align="center">
          <img src="./static/images/passk.png" class="center" width="80%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li><strong>RAST increases solution diversity</strong>, as evidenced by consistent pass@k improvements with larger <code>k</code>, enabling broader exploration and higher chances of capturing correct answers.</li>
            <li><strong>It can surpass RL-trained models</strong>, achieving pass@k accuracy that matches or exceeds the ceiling performance, especially on complex benchmarks like AMC and MATH500.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Analysis</h2>
        <p align="center">
        <img src="./static/images/case_study.png" class="center" width="80%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li>RAST guides the base model to follow more deliberate reasoning patterns, such as proposing, testing, and verifying solutions, unlike the base which often outputs linear, error-prone steps.</li>
            <li>This shift is quantitatively supported by high KL divergence on reasoning-specific tokens (e.g., ‚Äúcheck‚Äù), reflecting effective activation of reasoning behavior.</li>
          </ul>
        </div>
        <p align="center">
          <img src="./static/images/analysis_overall.png" class="center" width="80%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li>Cosine similarity between delta logits from different model scales serves as a strong indicator of transferability. Higher similarity correlates with better recovery rates, suggesting more effective reasoning activation.</li>
            <li>RAST achieves high reasoning performance while significantly reducing GPU memory and hardware requirements‚Äîup to 50% savings compared to full-scale RL‚Äîdemonstrating strong efficiency without sacrificing recovery rates.</li>
          </ul>
        </div>
        <p align="center">
          <img src="./static/images/parameters.png" class="center" width="80%">
        </p>
        <div class="content has-text-justified">
          <ul>
            <li>RAST maintains strong performance across a wide range of decoding-time hyperparameters.</li>
            <li>It is robust to variations in temperature (œÑ) and weight (Œª), eliminating the need for heavy hyperparameter tuning.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-------------------------------------------------------------------- Error Example  -------------------------------------------------------------------->
<!-- <section> -->

  <!-- <div class="column is-full has-text-centered content">
    <div id="examples" class="carousel results-carousel">
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/example_1.png" alt="statistics 3" width="80%"/>
          <p> Accuracy distribution of GPT4-V on the knowledge points of SceMQA </p>    
          </div>
        </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/example_2.png" alt="statistics 2" width="80%"/>
          <p> Accuracy distribution of Google Gemini on the knowledge points of SceMQA </p>
        </div>
      </div>
    </div>
  </div> -->


  <!-- <div class="columns is-centered m-6">
    <div class="column is-full has-text-centered content">
      <h2 class="title is-3" id="examples">Examples</h2>
      <img src="static/images/example.png" alt="error examples" width="80%"/>
      </div>
    </div>
  </div>
  </div> -->
 <!-- </section>  -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{ouyang2024structured,
      title={Reasoning Activation in LLMs via Small Model Transfer}, 
      author={Siru Ouyang and Zhuosheng Zhang and Bing Yan and Xuan Liu and Yejin Choi and Jiawei Han and Lianhui Qin},
      year={2025},
      eprint={2311.09656},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-6">
        <div class="content">
          <p>
            The source code of this webpage is based on the <a href="https://github.com/nerfies/nerfies.github.io/">
              Nerfies</a> project webpage.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
